{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cf76e0",
   "metadata": {},
   "source": [
    "# üõçÔ∏è Retail Store Sales ‚Äì Exploratory Data Analysis (EDA)\n",
    "Este an√°lisis explora un conjunto de datos de ventas de una tienda retail, con el objetivo de descubrir patrones, tendencias y posibles oportunidades de negocio.\n",
    "\n",
    "#PASO 1: CARGUE Y LIMPIEZA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646221d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_ID Customer_ID       Category          Item  Price_Per_Unit  \\\n",
      "0    TXN_6867343     CUST_09     Patisserie   Item_10_PAT            18.5   \n",
      "1    TXN_3731986     CUST_22  Milk Products  Item_17_MILK            29.0   \n",
      "2    TXN_9303719     CUST_02       Butchers   Item_12_BUT            21.5   \n",
      "3    TXN_9458126     CUST_06      Beverages   Item_16_BEV            27.5   \n",
      "4    TXN_4575373     CUST_05           Food   Item_6_FOOD            12.5   \n",
      "\n",
      "   Quantity  Total_Spent  Payment_Method Location Transaction_Date  \\\n",
      "0      10.0        185.0  Digital Wallet   Online       2024-04-08   \n",
      "1       9.0        261.0  Digital Wallet   Online       2023-07-23   \n",
      "2       2.0         43.0     Credit Card   Online       2022-10-05   \n",
      "3       9.0        247.5     Credit Card   Online       2022-05-07   \n",
      "4       7.0         87.5  Digital Wallet   Online       2022-10-02   \n",
      "\n",
      "  Discount_Applied  \n",
      "0             True  \n",
      "1             True  \n",
      "2            False  \n",
      "3              NaN  \n",
      "4            False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "retail_store_sale=pd.read_csv('retail_store_sales.csv')\n",
    "print(retail_store_sale.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751274db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12575 entries, 0 to 12574\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Transaction_ID    12575 non-null  object \n",
      " 1   Customer_ID       12575 non-null  object \n",
      " 2   Category          12575 non-null  object \n",
      " 3   Item              11362 non-null  object \n",
      " 4   Price_Per_Unit    11966 non-null  float64\n",
      " 5   Quantity          11971 non-null  float64\n",
      " 6   Total_Spent       11971 non-null  float64\n",
      " 7   Payment_Method    12575 non-null  object \n",
      " 8   Location          12575 non-null  object \n",
      " 9   Transaction_Date  12575 non-null  object \n",
      " 10  Discount_Applied  8376 non-null   object \n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(retail_store_sale.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32787790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Price_Per_Unit      Quantity   Total_Spent  \\\n",
      "count    11966.000000  11971.000000  11971.000000   \n",
      "mean        23.365912      5.536380    129.652577   \n",
      "min          5.000000      1.000000      5.000000   \n",
      "25%         14.000000      3.000000     51.000000   \n",
      "50%         23.000000      6.000000    108.500000   \n",
      "75%         33.500000      8.000000    192.000000   \n",
      "max         41.000000     10.000000    410.000000   \n",
      "std         10.743519      2.857883     94.750697   \n",
      "\n",
      "                    Transaction_Date  \n",
      "count                          12575  \n",
      "mean   2023-07-12 20:23:41.105368064  \n",
      "min              2022-01-01 00:00:00  \n",
      "25%              2022-09-30 00:00:00  \n",
      "50%              2023-07-13 00:00:00  \n",
      "75%              2024-04-24 00:00:00  \n",
      "max              2025-01-18 00:00:00  \n",
      "std                              NaN  \n"
     ]
    }
   ],
   "source": [
    "#We can see that Transaction_Date column is object, we need to change it to datetime format\n",
    "retail_store_sale['Transaction_Date']=pd.to_datetime(retail_store_sale['Transaction_Date'])\n",
    "\n",
    "print(retail_store_sale.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b366b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#CHECK FOR DUPLICATES\n",
    "print(retail_store_sale.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26a257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transaction_ID', 'Customer_ID', 'Category', 'Item', 'Payment_Method', 'Location', 'Discount_Applied']\n"
     ]
    }
   ],
   "source": [
    "#Standardize text data: Remove white spaces\n",
    "\n",
    "#Get a list of every object datatype columns.\n",
    "columns=retail_store_sale.select_dtypes('object').columns.tolist()\n",
    "print(columns)\n",
    "#For loop apply strip (Delete white spaces at beginning and end) of all object columns.\n",
    "for col in columns:\n",
    "    retail_store_sale[col]=retail_store_sale[col].astype(str).str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d07c49",
   "metadata": {},
   "source": [
    "NULL VALUES\n",
    "According to the INFO box, the following columns have NULLs: Item, Price_Per_Unit, Quantity, Total_Spent and Discount_Applied\n",
    "\n",
    "Category, Item and Price_Per_Unit are related. Is probably that items in the same category dont have the same price, and then, I can fill the missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e30fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction_ID        0\n",
      "Customer_ID           0\n",
      "Category              0\n",
      "Item                609\n",
      "Price_Per_Unit      609\n",
      "Quantity              0\n",
      "Total_Spent           0\n",
      "Payment_Method        0\n",
      "Location              0\n",
      "Transaction_Date      0\n",
      "Discount_Applied    205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a Copy if I miss something\n",
    "retail_item=retail_store_sale.copy()\n",
    "#Replace NaN, nan, NAN strings and empty cells, \" \" cells, for actual NaN values in all the Database.\n",
    "retail_item= retail_item.replace(r'^\\s*$', np.nan, regex=True)\n",
    "retail_item= retail_item.replace(['nan', 'NaN', 'NAN'], np.nan)\n",
    "\n",
    "#Checking that items in the same category dont have the same price\n",
    "df_clean = retail_item.dropna()\n",
    "check = df_clean.groupby(['Category', 'Price_Per_Unit'])['Item'].nunique()\n",
    "#print(check[check > 1])\n",
    "#As there are only 1 item with the same price in the category, we can match the NaN values of Item and Price_Per_Unit with a table of the correct values\n",
    "df_correct_flat = df_clean.groupby(['Category', 'Price_Per_Unit'])['Item'].unique().explode().reset_index()  #This line create a dataframe of the unique combinations of category, price and item, item being an array. Explode quits the agrupations and give a singular value to each row. Reset index makes all columns real columns again, due to the group by\n",
    "#print(df_correct_flat)\n",
    "\n",
    "#Match the Item / Price_Per_Unit value for the combination of Category and Item / Price_Per_Unit. As it is a merge, the column is added at the end.\n",
    "item_price=['Item','Price_Per_Unit']\n",
    "#For that adjust NaN for Item and Price_Per_Unit cols at the same line\n",
    "for col in item_price:\n",
    "    #If for the ON argument of the merge\n",
    "    if col == \"Item\":\n",
    "        on_col=['Category','Price_Per_Unit']\n",
    "    else:\n",
    "        on_col=['Category','Item']\n",
    "    # Merge of the correct Item/Price_Per_Unit column\n",
    "    retail_item=pd.merge(retail_item,df_correct_flat,how='left',on=on_col,suffixes=(\"\",\"_correct\"))\n",
    "    #Now, we need to fillna values of Item and Price_Per_Unit with the values of \"_correct\" column\n",
    "    retail_item[col]=retail_item[col].fillna(retail_item[f'{col}_correct'])\n",
    "    #Delete the _correct column\n",
    "    retail_item.drop(columns=[f'{col}_correct'], inplace=True)\n",
    "\n",
    "#Check if the remaning nulls of Item and Price_Per_Unit are the same\n",
    "\n",
    "null_itemprice=retail_item[(retail_item['Item'].isnull()) & (retail_item['Price_Per_Unit'].isnull())].isnull().sum()\n",
    "\n",
    "print(null_itemprice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435b16a",
   "metadata": {},
   "source": [
    "The remaining NaN in Item and Price Per Unit are in the columns in which the two columns are NaN, so the merge doesnt work.\n",
    "There are still NaN on those 2 columns, but also in Quantity, Total_Spent and Discount_Applied.\n",
    "As before between Item, Price_Per_Unit and Quantity, there is a relation between Price_Per_Unit, Quantity and Total_Spent. So we can use a similar logic to aproach this NaN's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4264551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction_ID         0\n",
      "Customer_ID            0\n",
      "Category               0\n",
      "Item                   0\n",
      "Price_Per_Unit         0\n",
      "Quantity             604\n",
      "Total_Spent          604\n",
      "Payment_Method         0\n",
      "Location               0\n",
      "Transaction_Date       0\n",
      "Discount_Applied    4199\n",
      "dtype: int64\n",
      "4.8 %\n",
      "Transaction_ID         0\n",
      "Customer_ID            0\n",
      "Category               0\n",
      "Item                   0\n",
      "Price_Per_Unit         0\n",
      "Quantity               0\n",
      "Total_Spent            0\n",
      "Payment_Method         0\n",
      "Location               0\n",
      "Transaction_Date       0\n",
      "Discount_Applied    3988\n",
      "dtype: int64\n",
      "Transaction_ID      0\n",
      "Customer_ID         0\n",
      "Category            0\n",
      "Item                0\n",
      "Price_Per_Unit      0\n",
      "Quantity            0\n",
      "Total_Spent         0\n",
      "Payment_Method      0\n",
      "Location            0\n",
      "Transaction_Date    0\n",
      "Discount_Applied    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a copy of the retail_item table\n",
    "retail_quantity=retail_item.copy()\n",
    "#Total_Spent=Price_Per_Unit * Quantity     -- We can get these 3 variables from this formula:\n",
    "#FILLING Price_Per_Unit, Quantity and Total_Spent. FOR LOOP runs through the list, in which an if statement performs the correct operation depending on the value of col\n",
    "nan_cols=['Price_Per_Unit','Quantity','Total_Spent']\n",
    "for col in nan_cols:\n",
    "    if col == \"Price_Per_Unit\":\n",
    "        retail_quantity[f'Fill_{col}']=retail_quantity['Total_Spent'] / retail_quantity['Quantity']\n",
    "    elif col == \"Quantity\":\n",
    "        retail_quantity[f'Fill_{col}']=retail_quantity['Total_Spent'] / retail_quantity['Price_Per_Unit']\n",
    "    else:\n",
    "        retail_quantity[f'Fill_{col}']=retail_quantity['Quantity'] * retail_quantity['Price_Per_Unit']\n",
    "    #Fill NaN based on the col value.\n",
    "    retail_quantity[col]=retail_quantity[col].fillna(retail_quantity[f'Fill_{col}'])\n",
    "    #Drop the created columns.\n",
    "    retail_quantity.drop(columns=[f'Fill_{col}'], inplace=True)\n",
    "\n",
    "#At this point, all the NaN of Price_Per_Unit where filled, also the majority of Quantity and Total_Spent, whose remaining NaNs are because there are NaN in both columns in the rows, so the operations return NaN\n",
    "#As we know now all the Price_Per_Unit, we can fill the remaining NaN of the Item column, by merging the same as in the previous step.\n",
    "\n",
    "retail_quantity=pd.merge(retail_quantity,df_correct_flat,how='left',on=['Category','Price_Per_Unit'],suffixes=(\"\",\"_correct\"))\n",
    "#Now, we need to fillna values of Item with the values of \"_correct\" column\n",
    "retail_quantity['Item']=retail_quantity['Item'].fillna(retail_quantity['Item_correct'])\n",
    "#Delete the _correct column\n",
    "retail_quantity.drop(columns=['Item_correct'], inplace=True)\n",
    "\n",
    "print(retail_quantity.isnull().sum())\n",
    "\n",
    "#As I said before, the remaining Quantity and Total_Spent NaN are in rows in which the 2 columns are NaN. There are no relations to fill them\n",
    "#If the total NaN rows are less than 5% of the total dataframe, i'll delete them. Otherwise I can fill forward or with an aggregation.\n",
    "\n",
    "print(f'{np.round((retail_quantity['Quantity'].isnull().sum()/len(retail_quantity))*100,2)} %') \n",
    "\n",
    "#Is less than 5%, so I can drop those rows, as without the Total_Spent value are not useful for a posterior analysis\n",
    "\n",
    "retail_quantity.dropna(subset=['Quantity'], inplace=True)\n",
    "print(retail_quantity.isnull().sum())\n",
    "\n",
    "#Finally, only Discount_Applied has NaN values. This column is not so useful for analysis, so I can just fill with the mode.\n",
    "\n",
    "mode_val = retail_quantity['Discount_Applied'].mode(dropna=True)[0]\n",
    "retail_quantity['Discount_Applied'] = retail_quantity['Discount_Applied'].fillna(mode_val)\n",
    "\n",
    "#print(retail_quantity['Discount_Applied'].value_counts())\n",
    "\n",
    "#Now, there are not NaN's in our dataframe, and we can start an EDA.\n",
    "\n",
    "print(retail_quantity.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef3d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
